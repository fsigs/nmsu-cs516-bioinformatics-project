---
title: "Frequent k-mers in the SARS-CoV-2 Genome"
subtitle: "CS516 Bioinformatics - Project 1"
author: "Israel Gonzalez S., Gabriel Romero"
date: "February 22, 2023"
toc: true
format:
  html:
    html-math-method: katex
    code-tools: true
    self-contained: true
execute:
  warning: false
---
# Abstract
Project 1 consists of implementing algorithms for finding frequent k-mers.  Understanding runtimes of all algorithms used by comparing the empirical runtime of algorithms used to show runtime increases of functions of sequence length L and k.

The next tasks included finding the most frequent k-mers in the SARS-CoV and SARS-CoV-2 genome.  Interpretation of results to provide any signifiers toward a biological understanding of Covid.  Next we developed a permutation test to determine the statistical significance of the frequency of most frequenct kmers with the SARS-CoV-2 genome sequence.  Followed by comparing the SARS Covid genome sequences to identify any major differences and potential biological interpretation.  Lastly, we found larger k-mer repeats beyond 15-mers found in both SARS-CoV-2 and SARS-CoV.    

# Introduction
Understanding nucleotides and genomes can be a seemingly impossible question to answer.  The reality of the fact is there are many solutions to solve the seemingly endless problems that are related to proteins, and other genomic structures.  Solutions that require a variety of scientific fields to combine expertise to solve one of the worlds most complex problems.  In particular, bioinformatics is evolving to explain biology motivated questions into information to address molecular biology.  This includes implementing algorithms such as sequence alignment, pattern matching, and genome assembly.  Lastly, it is important to evaluate the performance of algorithms and data structures on real data sets to solve these biological motivated questions.  This project was a stepping stone in motivation and understanding for the field of bioinformatics.   

# Methods
We proceed in this section to describe the methods we have implemented in the Python class FrequentKmers and the way they can be used in an executable Python file main.py

## Code
The methods are organized in the way each task required. First, we have the methods related to Tasks 1 and Task 2 that require to code the pseudo code we have in *Bioinformatics Algorithmsâ€“An Active Learning Approach, 3rd Edition*.

The class encapsulates all methods is:

```python
class FrequentKmers:
```

```python
  # Frequent Words Algorithm methods:
  def frequent_words(self, text, k):
    start = timer()
    frequent_words = []
    n = len(text)
    count_array = np.zeros(n - k + 1)
    for i in range(n - k + 1):
      pattern = text[i:i+k]
      count_array[i] = self.pattern_count(text, pattern)
    for i in self.max_array(count_array):
      frequent_words.append(text[i:i+k])
    frequent_words = self.remove_duplicates(frequent_words)
    end = timer()
    return [frequent_words,  round((end - start) * 1000, 3)]
  
  def pattern_count(self, text, pattern):
    count = 0
    for i in range(len(text) - len(pattern) + 1):
      if text[i:i+len(pattern)] == pattern:
        count += 1
    return count
  
  def remove_duplicates(self, arr):
    answer = []
    for item in arr:
      if item not in answer:
        answer.append(item)
    return answer

  def max_array(self, arr):
    max_val = max(arr)
    max_indices = [i for i, val in enumerate(arr) if val == max_val]
    return max_indices
```

The `FrequentKmers.frequent_words` method takes as parameters `text` and `k` representing the DNA sequence and the length of k-mer respectively. Taking text slices of length k, we *count* the frequency of each k-mer using `FrequentKmers.pattern_count` method. After counting them, we determine the k-mers with a maximum frequency count using `FrequentKmers.max_array` and filter them in a unique list of frequent_words without repetitions using `FrequentKmers.remove_duplicates`. We answer this list plus the running time taken in miliseconds.

```python

  # Better Frequent Words Algorithm methods:
  def better_frequent_words(self, text, k):
    start = timer()
    freq_map = self.frequent_map(text, k)
    if freq_map is not None:
      max_count = max(freq_map.values())
      frequent_words = []
      for pattern in freq_map.items():
        if pattern[1] == max_count:
          frequent_words.append(pattern[0])
      end = timer()
      return [frequent_words, round((end - start) * 1000, 3)]
    else:
      end = timer()
      return[None, round((end - start) * 1000, 3)]
  
  def frequent_map(self, text, k):
    freq_map = {}
    n = len(text)
    for i in range(n - k + 1):
      pattern = text[i:i+k]
      if pattern in freq_map:
        freq_map[pattern] += 1
      else:
        freq_map[pattern] = 1
    return freq_map
```
Similarly, the `FrequentKmers.better_frequent_words` method takes as parameters `text` and `k` representing the DNA sequence and the length of k-mer respectively. Taking text slices of length k, we create a hash map with the patterns as their index and count their frequency as its value using the method `FrequentKmers.frequent_map`. After, for each pattern, we choose the one with the maximum frecuency, adding it to the frequent_words list. We answer this list plus the running time taken in miliseconds.

```python
  # Random DNA generator method:
  def generate_dna(self, L):
    return ''.join(np.random.choice(['A', 'C', 'G', 'T'], size=L, p=[0.25, 0.25, 0.25, 0.25]))
```
The `FrequentKmers.generate_dna` method generates a random DNA sequence of a given length *L*. For this, it uses the Numpy choice function inside the library np.random. This generation uses a flat probability of 0.25 for each one of the characters of the nucleotides A, C, G, T; answering an array of chars. Then, we consolidate in a single string using the string function join. 

```python
  # Removes polyA tail
  def remove_polyA(self, sequence, tail_length):
    pattern = "A{" + str(tail_length) + ",}$"
    match = re.search(pattern, sequence)
    if match:
      sequence = sequence[:(match.start())]
    return sequence
```
The `FrequentKmers.remove_polyA` method removes polyA tails if a Genome, like in this project, has several A in its composition so we avoid that repetitive A's constitute the most frequent k-mers. This method defines a regular epression where we find in the DNA sequence a substring of tail_length. If the regular expression matches correctly, that substring is removed from the original sequence.

```python
  # Reader of Covid genome files:
  def get_covid_genome(self, filename):
    with open(filename, 'r') as file:
      sequence = file.read().replace('\n', '').strip()
    tail_length = 10
    if(filename == "SARS-CoV-2.txt"):
      tail_length = 33
    if(filename == "SARS-CoV.txt"):
      tail_length = 24
    return self.remove_polyA(sequence, tail_length)
```
The `FrequentKmers.get_covid_genome` method chooses if the dataset is SARS-CoV-2 or SARS-CoV, making them a single block of characters removing the breaklines. Also, for the reasons previously mentioned, it removes from the DNA sequence the polyA if it is present with the help of `remove_polyA` method.

```python
  # Permutation test (null distribution):
  def permutation_test(self, text, k, num_perm):
    p_value = None
    fm = self.frequent_map(text, k)
    max_count = max(fm.values())
    null_population = list(text)
    null_distribution = []
    for _ in range(num_perm):
      random.shuffle(null_population)
      fm2 = self.frequent_map(''.join(null_population), k)
      null_counts = max(fm2.values())
      null_distribution.append(null_counts)
    sum_ = sum(null_elem >= max_count for null_elem in null_distribution)
    p_value = (sum_ + 1) / (num_perm + 1)
    return p_value
```
The `FrequentKmers.permutation_test` method in base of the DNA sequence (text), a k length (k), and a number of iterations, it generates randomly several new DNA sequences by suffling the original text characters during the indicated iterations. It takes what are the most frequent kmers in this shuffled scenario. Then, it took a predictor value to represent how significant are these frequent k lengths in comparison with the original ones.

## Execution
To exercise correctly these methods, we have developed a `main.py` program. The following are the steps for its execution

* Unzip this project on a path where Python 3.8 or superior is active
* Open a console and go to where the unzipped folder is. make sure you are in the same level where the `main.py` program is. You can be sure of this printing the directory content with `ls` command
* Run the program with the command `py main.py`
* The program will produce exctly each one of the output, plots, and tables the following section has in its analysis

**Important note**: Make sure you have installed the following Python 3 modules/libraries before:
pandas, matplotlib, numpy, pprint, random, re, and timeit.

# Results
In this section, we proceed to describe our results. We have structured this section in the same schema the project tasks appears in the project prompt.

## Algorithms for finding frequent k-mers
### Task 1. Frequent words by counting
This is the output of our program:

> ============================================ \
> Task 1: Algorithm Frequent Words (counting) \
> ============================================ \
> Using test cases from class slides (Ch 1 slides 64 and 99), \
> we show the list of frequent words and running time in ms for our implementation are correct: \
> [['ACG', 'TTT'], 0.163] \
> [['atgatcaag', 'ctcttgatc', 'tcttgatca', 'cttgatcat'], 89.532] \

The first algorithm used is a counting method for frequent words.  It is straightforward in finding the most frequent kmers.  Interpretation of the results found that the most frequent kmer were "9-mers".

Understanding these results are key contribution to the field of bioinformatics.  Considering the many fields involved in the solving of "hidden messages" in these strings of 4 lettered texts, it is important that we understand what these frequent alignments mean. 

According to biological experiments, bacterial DnaA boxes are usually nine nucleotides long.  The likelihood of four 9-mers showing up in a genome sequence leads to the hypothesis that one of these four 9-mers might represent a potential DnaA box. 

However, before concluding that this is a DnaA box, we would still need to sequence other short regions in the genome to determine if these strings exhibit throughout the entire genome. If these strings are exhibited throughout the genome, rather than just in the ori region, then the results are considered insignificant.


### Task 2. Frequent words by hashing
This is the output of our program:

> ================================================= \
> Task 2: Algorithm Better Frequent Words (hashing) \
> ================================================= \
> Using test cases from class slides (Ch 1 slides 64 and 99), \
> we show the list of frequent words and running time in ms for our implementation are correct: \
> [['ACG', 'TTT'], 0.1] \
> [['atgatcaag', 'ctcttgatc', 'tcttgatca', 'cttgatcat'], 0.792] \

When analyzing the hashing algorithm, the results of finding the most and longest kmers are exactly the same.  This is reassuring, because the problem was solved with exact correspondance of finding the most frequent kmers with the previous counting algorithm.  However, when looking at the algorithm analysis of the hashing method, the runtime is significantly lower than the counting method.  Now, this significant low runtime can answer a significant problem in the bioinformational question that arises.  The counting method is efficient for small string genomes, however the upper bound runtime of |Text|^2 makes it extrememly slow for larger string texts.  Since more short region sequencing throughout the genome is required to determine a potential DnaA box, this algorithm is the optimal and efficient choice in finding significant results from an extremely long genome data string. 

## Understanding the runtime
### Task 3. Method generates random DNA sequences of several random lengths
This is the output of our program:

> ======================================== \
> Task 3: Generating Random DNA Sequences \
> ======================================== \
> Using Numpy random choice function of Python, \
> we generate 10 random DNA sequences of variable lenght: \
> 'GACTCGGATATGT' \
> 'GAATATGTGCAA' \
> 'AGGGGATACTACT' \
> 'GTACATATCA' \
> 'TTGGGATAACA' \
> 'GTGGGAAGCACGT' \
> 'ACATACAGACGCA' \
> 'ATTCTTAACAAGGC' \
> 'CTATTGAAAG' \
> 'TCCGTAGGTCT' \



### Task 4. Analysis of empirical time comparing counting and hashing algorithms
To empirically compare the two algorithms in terms of runtime, our program for this analysis has produced the comparison in the following charts, and also consolidated everything in a major table with these results.

The following are our charts:

::: {#fig-scenario layout-ncol=2}

![L25](images/q4_25.png){#q4_25}

![L50](images/q4_50.png){#q4_50}

![L75](images/q4_75.png){#q4_75}

![L100](images/q4_100.png){#q4_100}

![L250](images/q4_75.png){#q4_250}

![L500](images/q4_500.png){#q4_500}

![L750](images/q4_750.png){#q4_750}

![L1000](images/q4_1000.png){#q4_1000}

Runtime comparison using a Random Genome length of 25, 50, 75, 100, 250, 500, 750, and 1000 nucleotides, and k-lengths of 3, 6, 9, 12, and 15
:::

And in a consolidated table:

|Length|K-length|FW(ms)|BFW(ms)|
|:----:|:---:|:-----:|:------:|
| 25 | 3 | 0.369 | 0.04 |
| 25 | 6 | 0.263 | 0.029 |
| 25 | 9 | 0.201 | 0.026 |
| 25 | 12 | 0.148 | 0.022 |
| 25 | 15 | 0.117 | 0.019 |
| 50 | 3 | 2.672 | 0.107 |
| 50 | 6 | 2.848 | 0.149 |
| 50 | 9 | 2.291 | 0.121 |
| 50 | 12 | 1.878 | 0.132 |
| 50 | 15 | 1.687 | 0.112 |
| 75 | 3 | 7.455 | 0.151 |
| 75 | 6 | 7.312 | 0.224 |
| 75 | 9 | 5.965 | 0.155 |
| 75 | 12 | 6.064 | 0.214 |
| 75 | 15 | 6.115 | 0.143 |
| 100 | 3 | 9.436 | 0.21 |
| 100 | 6 | 10.619 | 0.19 |
| 100 | 9 | 9.054 | 0.316 |
| 100 | 12 | 7.918 | 0.24 |
| 100 | 15 | 6.889 | 0.117 |
| 250 | 3 | 55.049 | 0.269 |
| 250 | 6 | 35.782 | 0.282 |
| 250 | 9 | 42.438 | 0.283 |
| 250 | 12 | 26.598 | 0.276 |
| 250 | 15 | 27.295 | 0.288 |
| 500 | 3 | 198.86 | 0.467 |
| 500 | 6 | 125.661 | 0.563 |
| 500 | 9 | 156.53 | 0.874 |
| 500 | 12 | 157.304 | 0.867 |
| 500 | 15 | 157.182 | 2.094 |
| 750 | 3 | 334.105 | 0.696 |
| 750 | 6 | 261.337 | 0.798 |
| 750 | 9 | 291.711 | 0.824 |
| 750 | 12 | 259.805 | 0.803 |
| 750 | 15 | 268.239 | 0.808 |
| 1000 | 3 | 602.367 | 0.915 |
| 1000 | 6 | 501.437 | 1.017 |
| 1000 | 9 | 475.136 | 0.967 |
| 1000 | 12 | 476.967 | 1.067 |
| 1000 | 15 | 472.738 | 1.058 |

Analyzing the empirical time comparisin of the two algorithms.  It is clear that the runtime, in milliseconds, of the counting method implementation increases significantly as the function of sequence length L increases.

Looking at the consolidated table, no matter the increase of sequence length L, the runtime of the hashing algorithm stays suprisingly close to its mean.  The upper bound of the count algorithm O(|Text|^2 * k) versus the O(n)+1 hashing algorithm runtime, makes hashing the most efficient and optimal implementation of finding frequent kmer patterns.

## Frequent k-mers in the SARS-Cov-2 genome
### Task 5 and Task E2. SARS-CoV-2 and SARS-CoV most frequent k-mers

The following is a table of the most frequent k-mers present in the SARS-CoV-2 and SARS-CoV genomes:

|Genome|K-length|K-mer|
|:----:|:---:|:-----:|
| SARS-CoV-2 | 3 | TTT |
| SARS-CoV-2 | 6 | TTGTTA |
| SARS-CoV-2 | 9 | TAAACGAAC |
| SARS-CoV-2 | 12 | GTTGATGGTGTT |
| SARS-CoV-2 | 15 | ATCAGACAACTACTA |
| SARS-CoV-2 | 15 | TCAGACAACTACTAT |
| SARS-CoV-2 | 15 | CAGACAACTACTATT |
| SARS-CoV-2 | 15 | CAATTATTATAAGAA |
| SARS-CoV-2 | 15 | AATTATTATAAGAAA |
| SARS-CoV-2 | 15 | ATTATTATAAGAAAG |
| SARS-CoV-2 | 15 | TTGCAGAGTGGTTTT |
| SARS-CoV-2 | 15 | AAAGTTGATGGTGTT |
| SARS-CoV-2 | 15 | AAGTTGATGGTGTTG |
| SARS-CoV-2 | 15 | TAAACGAACATGAAA |
| SARS-CoV | 3 | TTT |
| SARS-CoV | 6 | TTGCTG |
| SARS-CoV | 9 | TAAACGAAC |
| SARS-CoV | 12 | TGAGGAAGAAGA |
| SARS-CoV | 12 | TAAAATGTCTGA |
| SARS-CoV | 15 | AAAAGAAAAAGACTG |
| SARS-CoV | 15 | AAAGAAAAAGACTGA |
| SARS-CoV | 15 | ATTATAATTATAAAT |

When comparing the most frequent k-mers of SARS-CoV-2 and SARS-CoV, the 15-mer shows up the most. 

### Task 6. Interpreting the k-mers found in a biological context
When putting the Kmers in the BLASTN database, no significant similarities where found.  In other words, there wasn't much alignment.  The differences in frequent 15mers between the RNA viruses might speak to their Phylogenetic differences and where the SARS originated from. 

## Extra Credits
### Task E1. The null distribution of the frequency of most frequent k-mers
Our program produced these results:

> ================================================================================ \
> E1: Null Distribution of the most frequent k-mers in SARS-CoV-2 genome sequence \
> ================================================================================ \
> Using the SARS-CoV-2 genome sequence, our permutation test \
> with 1000 permutations gives. We have considered a p-value threshold of 0.05 to decide \
> if the most frequent k-mer is unlikely to have occurred by chance alone \
> and consequently, it has biological significance: \
> 
> 3-mers give a p-value of 0.33067, then they DO NOT HAVE biological significance \
> 6-mers give a p-value of 0.34366, then they DO NOT HAVE biological significance \
> **9-mers give a p-value of 0.02198, then they DO HAVE biological significance** \
> **12-mers give a p-value of 0.09491, then they DO NOT HAVE biological significance** \
> 15-mers give a p-value of 0.52248, then they DO NOT HAVE biological significance \

When looking at the p-value threshold of 0.05, there is one kmer that has bilogical significance, the 9-mers.  The p-value of the SARS-CoV-2 9-mers was 0.02198, which is of significance when comparing it to the 0.05 threshold.   Initially, the relevance of 9-mers traces back to the recurrence of a potential DnaA box in a DNA genome.  In reality it is important to undertand that Covid is involved in RNA metabolization, not DNA metabolization.
One other possible significant biological finding was the 12-mer p-value threshold value of 0.9491.  Even though the p-value was higher than 0.05, we know that nonrandom findings in kmer sequencing could have possible biological value if it is unlikely to have occurred by chance alone.

### Task E2. SARS-CoV versus SARS-CoV-2
Analyzed above in Task 5. Please, go to that section.

### Task E3. Find the longest k-mer repeats beyond 15
First, we find what is the max value for k in each Genome:

|Genome|K-length|# matches|
|:----:|:---:|:-----:|
| SARS-CoV-2 | 15 | 10 |
| SARS-CoV-2 | 16 | 5 |
| SARS-CoV-2 | 17 | 2 |
| SARS-CoV | 15 | 3 |
| SARS-CoV | 16 | 1 |

Now, that we know for SARS-CoV-2 is k=17 and for SARS-CoV is K=16, we found the longest kmers:
Longest k-mers in SARS-CoV-2:  ['ATCAGACAACTACTATT', 'CAATTATTATAAGAAAG']
Longest k-mers in SARS-CoV  :  ['AAAAGAAAAAGACTGA']

Understanding the first longest kmer for SARS-CoV-2, was a K-length of 17 and only 2 number of matches of the genome may signify a logical biomechanism of where is unlikely to occur. However there would have to be more explanation of other short sequences throughout the RNA genome to determine any validity of the short occurance.

However a more unlikely occurance happened in the the kmer of K-length 16, with 1 match of the SARs-CoV RNA genome.  This is the most unlikely occurance happening when finding the longest k-mers found in both SARS-CoV 2 and SARS-CoV-2. 

# Discussion
Did we find a DnaA box in Task 1 and 2?
What can the k-mers found in The SARS-CoV-2 Genome tell us about the evolution of Covid?

# Distribution of work
Lead Programmer Israel Gonzalez Sr
Lead Author Gabriel Romero

# References
https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome

https://www.ncbi.nlm.nih.gov/nuccore/NC_045512

https://www.sciencedirect.com/topics/medicine-and-dentistry/rna-processing